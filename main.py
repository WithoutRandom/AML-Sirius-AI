# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbO5aqVhkPRcpOe-dHsOIiPfKztfFW-A

## Пакетики
"""

!pip install dune-client

"""##Сбор датасета

Для сбора датасета будем использовать внутреннее API chainabuse.com.
Почему-то GraphQL вместо REST :LOL. Может быть это обосновано высокой связностью и вложненностью данных.
Обнаружен случайно в процессе веб сниффинга сайта с репортами.

Блок импортов
"""

import requests
import tqdm
import pandas as pd
from dune_client.types import QueryParameter
from dune_client.client import DuneClient
from dune_client.query import QueryBase

"""Объявим массив для хранения списка недобросовестных BTC адресов.
В дальнейшем будем использовать его длину для контроля выполнения.
"""

btc_addresses = []

"""Поработаем с cURL для казуалов - requests.
Используем реальные headers, UserAgent не влияет роли, но думаю лучше оставить честный UA.
"""

url = "https://www.chainabuse.com/api/graphql-proxy"

headers = {
    "User-Agent": "I-Parse-Your-Private-API",
    "Accept": "*/*",
    "Referer": "https://www.chainabuse.com/chain/BTC",
    "Origin": "https://www.chainabuse.com",
    "Connection": "keep-alive",
    "content-type": "application/json",
}

"""Тело post запроса разделено на 2 части, используя логику компилированных языков, чтобы каждый раз в теле цикла не инициализировать query.
Часть query статична и не меняется со временем, а часть variables (как следует из названия) состоит из переменных значений.

GraphQL raw запрос. Зачем использовать библиотеки?
"""

query = """
query GetReports($input: ReportsInput, $after: String, $before: String, $last: Float, $first: Float) {
  reports(
    input: $input
    after: $after
    before: $before
    last: $last
    first: $first
  ) {
    pageInfo {
      startCursor
      endCursor
    }
    edges {
      cursor
      node {
        ...Report      }
    }
    count
    totalCount
  }
}

fragment Report on Report {
  ...ReportAddresses
}

fragment ReportAddresses on Report {
  addresses {
    chain
    address
  }
}

"""

"""Обозначим необходимое количество адресов в датасете."""

need_count = 5000

"""Это точно не "магическое число", это последний блок с запроса сайта, можно автоматизировать, но при дальнейшей работе не понадобилось."""

first = "YXJyYXljb25uZWN0aW9uOjE0"

last_len = 0

with tqdm.tqdm(total=need_count) as pbar:
  while len(btc_addresses) < need_count:
    variables = {
        "input": {
            "chains": ["BTC"],
            "scamCategories": [],
            "orderBy": {
                "field": "CREATED_AT",
                "direction": "DESC"
            }
        },
        "first": 40, # Максимум - 50, со стороны сервера. Возьмём 40 чтобы числа были кратны 10.
        "after": first # Каждый раз запрашиваем с последнего из предыдущего блока. Повсеместная практика.
    }

    response = requests.post(url, json={'query': query, 'variables': variables}, headers=headers)
    data = response.json()['data']

    for edge in data['reports']['edges']:
        for address in edge['node']['addresses']:
            if address['chain'] == 'BTC':
                btc_addresses.append(address['address'])
    first = data['reports']['pageInfo']['endCursor']

    btc_addresses = list(set(btc_addresses))  # Удаление дубликатов, а они есть!
    pbar.update(len(btc_addresses)-last_len)
    last_len = len(btc_addresses)
print(len(btc_addresses), btc_addresses)

"""Сохраним собранный датасет адресов в pandas DataFrame и .csv файл."""

df = pd.DataFrame(btc_addresses, columns=['address'])
df['flag'] = 1

csv_file_path = 'set.csv'
df.to_csv(csv_file_path, index=False)

"""---

SELECT value, tx_id FROM bitcoin.outputs WHERE address IN ('', '')
SELECT value, tx_id FROM bitcoin.inputs WHERE address IN ('', '')

Теперь осталось собрать еще 5000 добросовестных btc адресов. Для этого будем использовать возможности сайта dune.com.

Я уже создал [SQL запрос](https://dune.com/queries/3576214) на сайте, так что теперь смогу получить результаты с помощью их api.
"""

dune = DuneClient("7FqecOkty3nDNFfKW9jpjjqUKwrgINIw")
query_result = dune.get_latest_result_dataframe(3576214) # Ограничение в 8000 строк, т.к есть строки с пустым адресом.
query_result

"""Данные не очень красивые, вытащим из этого только адреса."""

query_result['address'] = query_result['output'].apply(lambda x: x.split()[1][1:])
query_result['address'] = query_result['address'].apply(lambda x: None if x == '<nil>' else x) # Для dropna().
query_result = query_result.dropna()
query_result

"""Приведем "хорошую" таблицу к формату таблицы с недобросовестными адресами."""

good_df = pd.DataFrame()
good_df['address'] = query_result['address']
good_df['flag'] = 0 # Каждый из адресов является добросовестным (хотя не факт).
good_df

"""Объединим таблицы в одну."""

bad_df = pd.read_csv('set.csv')
result = pd.concat([bad_df, good_df], ignore_index=True)
result.drop_duplicates(subset=['address'], ignore_index=True) # Исключаем возможность отметки одного и того же адреса "плохим"
                                                              # и "хорошим" одновременно.
result

"""---



---

## Мусорка
"""

str(list(bad_df["address"])[400:500])[1:-1]

all_i_have = res_df.copy()
all_i_have

result_test = all_i_have.groupby('address').agg({'tx_id': list, 'value': list}).reset_index()

result_test

result_test.to_csv('bad_transactions.csv')

def get_address_info(address):
    try:
        url = f"https://blockchain.info/rawaddr/{address}"
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()

        transactions_hashes = [tx['hash'] for tx in data['txs']]
        transactions_outputs = [[out['addr'] for out in tx['out'] if 'addr' in out] for tx in data['txs']]
        transactions_inputs = [[inp['prev_out']['addr'] for inp in tx['inputs'] if 'prev_out' in inp and 'addr' in inp['prev_out']] for tx in data['txs']]
        total_received = data['total_received']
        total_sent = data['total_sent']

        return {
            'address': address,
            'transactions_hash': transactions_hashes,
            'transaction_outputs': transactions_outputs,
            'transaction_inputs': transactions_inputs,
            'total_received': total_received,
            'total_sent': total_sent
        }
    except requests.exceptions.HTTPError as e:
        print(f"HTTP Error for address {address}: {e}")
    except requests.exceptions.RequestException as e:
        print(f"Request Exception for address {address}: {e}")
    except ValueError as e:
        print(f"JSON Decode Error for address {address}: {e}")

address = 'bc1qyrqam7p7v5jqyna0lfcma2zn7h2fvsu5056trc'
get_address_info(address)