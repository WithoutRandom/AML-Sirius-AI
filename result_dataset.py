# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YWW7hnCfcyejtbn5J5wI6n1LcWLd_lPw
"""

import requests
import pandas as pd
from time import sleep
from tqdm import tqdm

def get_info_for_addresses(addresses):
    # Формируем URL.
    addresses_str = '|'.join(addresses)
    url = f"https://blockchain.info/multiaddr?active={addresses_str}"

    try:
        response = requests.get(url)
        response.raise_for_status()  # Проверяем на ошибки HTTP.
        data = response.json()

        # Подготавливаем данные для DataFrame.
        rows = []
        old_n_tx = 0
        for address_info in data['addresses']:
            address = address_info['address']
            total_received = address_info['total_received']
            total_sent = address_info['total_sent']

            # Получаем транзакции.
            transactions = []
            for i in range(old_n_tx, len(data['txs'])):
                if i > old_n_tx+address_info['n_tx']:
                  break
                transactions.append(data['txs'][i]['hash'])
            old_n_tx += address_info['n_tx']
            rows.append([address, transactions, total_received, total_sent])

        # Создаем DataFrame.
        df = pd.DataFrame(rows, columns=['address', 'transaction', 'total_received',
                                         'total_sent'])
        return df
    except requests.exceptions.HTTPError as e:
        print(f"\nHTTP Error: {e}")
        print(response.headers)
    except requests.exceptions.RequestException as e:
        print(f"\nRequest Exception: {e}")
    except ValueError as e:
        print(f"\nJSON Decode Error: {e}")


addresses_dataset = pd.read_csv('addresses_dataset.csv')
addresses = list(addresses_dataset['address'])
dataset = pd.DataFrame(columns=['address',  'transaction', 'total_received',
                                'total_sent'])

count = 300
pbar = tqdm(total=len(addresses))

while count < len(addresses):
    if (count+300) > len(addresses)-1:
        count = len(addresses)-1

    df = get_info_for_addresses(addresses[count-300:count])
    dataset = pd.concat([dataset, df], ignore_index=True)
    count += 300
    pbar.update(300)


print('Loading dataset...')
dataset = dataset.merge(addresses_dataset, how='inner', left_on='address', right_on='address')
dataset.to_csv('dataset.csv')
print('Done!!')